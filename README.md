# ğŸš€ Job Keywords Analyzer

Une application de scraping et d'analyse d'offres d'emploi utilisant l'intelligence artificielle pour extraire et analyser les compÃ©tences les plus demandÃ©es sur le marchÃ© du travail.

## ğŸ“‹ Table des matiÃ¨res

- [Vue d'ensemble](#vue-densemble)
- [Architecture](#architecture)
- [Technologies utilisÃ©es](#technologies-utilisÃ©es)
- [Installation rapide](#installation-rapide)
- [Guide de dÃ©veloppement](#guide-de-dÃ©veloppement)
- [Gestion Docker](#gestion-docker)
- [API Documentation](#api-documentation)
- [Contribution](#contribution)

## ğŸ¯ Vue d'ensemble

### Objectif
Automatiser la collecte et l'analyse des offres d'emploi pour identifier :
- Les compÃ©tences techniques les plus demandÃ©es
- Les tendances du marchÃ© de l'emploi
- Les Ã©volutions des technologies recherchÃ©es
- Les insights pour orienter la formation

### FonctionnalitÃ©s principales
- **Scraping automatisÃ©** : Collecte d'offres depuis Indeed, LinkedIn, etc.
- **Analyse NLP** : Extraction de mots-clÃ©s avec spaCy
- **API REST** : Exposition des donnÃ©es via FastAPI
- **Dashboard** : Visualisation des donnÃ©es avec React
- **Recherche avancÃ©e** : Moteur de recherche full-text avec Elasticsearch

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   React App     â”‚â”€â”€â”€â”€â”‚   FastAPI        â”‚â”€â”€â”€â”€â”‚   MySQL         â”‚
â”‚   (Frontend)    â”‚    â”‚   (API Gateway)  â”‚    â”‚   (Database)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Scrapy        â”‚â”€â”€â”€â”€â”‚   Redis Queue    â”‚â”€â”€â”€â”€â”‚   Elasticsearch â”‚
â”‚   (Scraper)     â”‚    â”‚   (Jobs)         â”‚    â”‚   (Search)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   spaCy NLP      â”‚
                       â”‚   (Analysis)     â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ Technologies utilisÃ©es

### Backend
- **Python 3.11+** : Langage principal
- **FastAPI** : Framework web moderne et rapide
- **Scrapy** : Framework de scraping robuste
- **spaCy** : Traitement du langage naturel
- **SQLAlchemy** : ORM pour la base de donnÃ©es
- **Redis + RQ** : File de tÃ¢ches asynchrones

### Base de donnÃ©es
- **MySQL 8.0** : Base de donnÃ©es relationnelle
- **Elasticsearch** : Moteur de recherche et analytics
- **Redis** : Cache et file de tÃ¢ches

### Frontend
- **React 18** : Interface utilisateur
- **Vite** : Bundler rapide
- **Tailwind CSS** : Framework CSS utilitaire
- **Recharts** : Graphiques et visualisations

### Infrastructure
- **Docker & Docker Compose** : Conteneurisation
- **NGINX** : Reverse proxy (production)

## ğŸš€ Installation rapide

### PrÃ©requis
- Docker et Docker Compose
- Python 3.11+ (pour le dÃ©veloppement)
- Node.js 18+ (pour le frontend)

### 1. Cloner le projet
```bash
git clone <url-repo>
cd job-keywords-analyzer
```

### 2. Configuration
```bash
# Copier le fichier d'environnement
cp .env.example .env

# Ã‰diter les variables selon vos besoins
nano .env
```

### 3. Lancement avec Docker
```bash
# DÃ©marrer tous les services
docker-compose up -d

# VÃ©rifier que tout fonctionne
docker-compose ps
```

### 4. AccÃ¨s aux services
- **API** : http://localhost:8000
- **Frontend** : http://localhost:3000
- **Elasticsearch** : http://localhost:9200
- **MySQL** : localhost:3306

## ğŸ§‘â€ğŸ’» Guide de dÃ©veloppement

### Structure du projet
```
job-keywords-analyzer/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api/              # FastAPI application
â”‚   â”œâ”€â”€ scraper/          # Scrapy spiders
â”‚   â”œâ”€â”€ nlp/              # Analyse NLP
â”‚   â””â”€â”€ models/           # ModÃ¨les de donnÃ©es
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/   # Composants React
â”‚   â”‚   â”œâ”€â”€ pages/        # Pages de l'application
â”‚   â”‚   â””â”€â”€ utils/        # Utilitaires
â”œâ”€â”€ docker/               # Configurations Docker
â”œâ”€â”€ docs/                 # Documentation
â””â”€â”€ tests/                # Tests automatisÃ©s
```

### DÃ©veloppement local

#### Backend
```bash
cd backend
python -m venv venv
source venv/bin/activate  # Linux/Mac
pip install -r requirements.txt
uvicorn api.main:app --reload --port 8000
```

#### Frontend
```bash
cd frontend
npm install
npm run dev
```

#### Base de donnÃ©es
```bash
# DÃ©marrer uniquement MySQL et Redis
docker-compose up -d mysql redis

# CrÃ©er les tables
cd backend
python -m alembic upgrade head
```

### Workflow de dÃ©veloppement

1. **DÃ©veloppement backend** : Modifiez le code dans `backend/`
2. **Tests** : `pytest backend/tests/`
3. **DÃ©veloppement frontend** : Modifiez le code dans `frontend/`
4. **Build & Test** : `docker-compose build && docker-compose up -d`

## ğŸ“Š API Documentation

L'API est automatiquement documentÃ©e via FastAPI :
- **Swagger UI** : http://localhost:8000/docs
- **ReDoc** : http://localhost:8000/redoc

### Endpoints principaux

#### Scraping
- `POST /api/scraper/start` : DÃ©marrer un scraping
- `GET /api/scraper/status/{job_id}` : Statut d'un job
- `GET /api/scraper/jobs` : Liste des offres collectÃ©es

#### Analyse
- `POST /api/analyze/job/{job_id}` : Analyser une offre
- `GET /api/analyze/keywords` : Top des mots-clÃ©s
- `GET /api/analyze/trends` : Tendances temporelles

#### Recherche
- `GET /api/search/jobs` : Rechercher des offres
- `GET /api/search/suggestions` : Suggestions de recherche

## ğŸ§ª Tests

```bash
# Tests backend
cd backend
pytest tests/ -v

# Tests frontend
cd frontend
npm test

# Tests d'intÃ©gration
docker-compose -f docker-compose.test.yml up --abort-on-container-exit
```

## ğŸ³ Gestion Docker

Pour gÃ©rer efficacement les conteneurs Docker et rÃ©soudre les conflits de ports, consultez notre documentation complÃ¨te :

ğŸ“– **[Guide complet de gestion Docker](docs/docker-management.md)**

### Script d'aide interactif
```bash
# Lancer le script d'aide Docker (recommandÃ©)
./docker-helper

# Ou directement
./scripts/docker-helper.sh
```

### Commandes essentielles
```bash
# Lister les conteneurs actifs
docker ps

# Identifier les conflits de ports
ss -tlnp | grep :3000

# ArrÃªter un conteneur spÃ©cifique
docker stop CONTAINER_NAME

# Nettoyer les conteneurs arrÃªtÃ©s
docker container prune
```

## ğŸ“ˆ Monitoring

### Logs
```bash
# Voir tous les logs
docker-compose logs -f

# Logs d'un service spÃ©cifique
docker-compose logs -f api
```

### MÃ©triques
- **Redis** : http://localhost:6379
- **MySQL** : Utilisez un client comme DBeaver
- **Elasticsearch** : http://localhost:9200/_cluster/health

## ğŸš€ DÃ©ploiement

### Production avec Docker
```bash
# Build des images de production
docker-compose -f docker-compose.prod.yml build

# DÃ©ploiement
docker-compose -f docker-compose.prod.yml up -d
```

### Variables d'environnement importantes
```env
# Base de donnÃ©es
MYSQL_ROOT_PASSWORD=your_secure_password
MYSQL_DATABASE=job_analyzer
MYSQL_USER=app_user
MYSQL_PASSWORD=app_password

# Redis
REDIS_PASSWORD=redis_password

# API
API_SECRET_KEY=your_secret_key_here
DEBUG=false

# Scraping
SCRAPING_DELAY=2000
MAX_CONCURRENT_JOBS=5
```

## ğŸ¤ Contribution

### Comment contribuer
1. Fork le projet
2. CrÃ©er une branche feature (`git checkout -b feature/nouvelle-fonctionnalite`)
3. Commit vos changements (`git commit -am 'Ajout nouvelle fonctionnalitÃ©'`)
4. Push vers la branche (`git push origin feature/nouvelle-fonctionnalite`)
5. CrÃ©er une Pull Request

### Standards de code
- **Python** : PEP 8, type hints, docstrings
- **JavaScript** : ESLint, Prettier
- **Commits** : Messages clairs en franÃ§ais
- **Tests** : Couverture minimale de 80%

## ğŸ“ Licence

Ce projet est sous licence MIT. Voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

## ğŸ“ Support

- **Issues** : Utilisez GitHub Issues
- **Documentation** : Consultez le dossier `docs/`
- **FAQ** : Voir `docs/FAQ.md`

---

**DÃ©veloppÃ© avec â¤ï¸ pour analyser le marchÃ© de l'emploi tech** 